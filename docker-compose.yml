services:
  # Simplified Zeek monitoring using container's default network interface
  zeek-live:
    build:
      context: ./services/zeek-monitor
      dockerfile: Dockerfile
    container_name: zeek-live-monitor
    restart: unless-stopped
    volumes:
      - ./services/zeek-monitor/config:/config
      - ./services/zeek-monitor/logs:/logs
      - ./services/zeek-monitor/scripts:/scripts
    env_file: .env
    command: /scripts/zeek-live-monitor.sh
    # Use default bridge network instead of host networking
    networks:
      - zeek-network
    # Still need some capabilities for packet capture
    cap_add:
      - NET_ADMIN
      - NET_RAW
    # Enable promiscuous mode for packet capture
    privileged: true

  # Simplified traffic simulator using default networking
  siem-simulator:
    build:
      context: ./services/simulator
      dockerfile: Dockerfile
    container_name: siem-simulator
    restart: unless-stopped
    volumes:
      - ./services/simulator/src:/src/simulator
      - ./services/fluentd/logs:/logs
    env_file: .env
    ports:
      - "8080:8080"
    cap_add:
      - NET_ADMIN
      - NET_RAW
    networks:
      - zeek-network
    command: python3 /src/simulator/simulator_server.py

  fluentd:
    build:
      context: ./services/fluentd
      dockerfile: Dockerfile
    container_name: fluentd
    restart: unless-stopped
    image: fluentd:custom
    ports:
      - "24224:24224"
      - "24224:24224/udp"
    volumes:
      - ./services/fluentd/conf:/fluentd/etc
      - ./services/fluentd/logs:/logs
    environment:
      - FLUENTD_CONF=fluentd.conf
    env_file: .env

  # PySpark Master
  spark-master:
    image: vastdataorg/spark-vast:latest
    container_name: spark-master
    restart: unless-stopped
    ports:
      - "8090:8080"  # Spark Master Web UI
      - "7077:7077"  # Spark Master port
    volumes:
      - ./services/pyspark/conf/spark-defaults.conf:/tmp/spark-defaults.conf.template
    networks:
      - zeek-network
    env_file: .env
    command: >
      bash -c '
        cat /tmp/spark-defaults.conf.template | sed -e "s|@@SPARK_NDB_ENDPOINT@@|\\${SPARK_NDB_ENDPOINT}|g; \
            s|@@SPARK_NDB_DATAENDPOINTS@@|\${SPARK_NDB_DATAENDPOINTS}|g; \
            s|@@SPARK_NDB_ACCESS_KEY_ID@@|\${SPARK_NDB_ACCESS_KEY_ID}|g; \
            s|@@SPARK_NDB_SECRET_ACCESS_KEY@@|\${SPARK_NDB_SECRET_ACCESS_KEY}|g" > /opt/spark/conf/spark-defaults.conf && /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master'
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master

  # PySpark Worker
  spark-worker:
    image: vastdataorg/spark-vast:latest
    container_name: spark-worker
    restart: unless-stopped
    ports:
      - "8081:8081"  # Spark Worker Web UI
    volumes:
      - ./services/pyspark/conf/spark-defaults.conf:/tmp/spark-defaults.conf.template
    networks:
      - zeek-network
    depends_on:
      - spark-master
    env_file: .env
    command: >
      bash -c '
        cat /tmp/spark-defaults.conf.template | sed -e "s|@@SPARK_NDB_ENDPOINT@@|\\${SPARK_NDB_ENDPOINT}|g; \
            s|@@SPARK_NDB_DATAENDPOINTS@@|\${SPARK_NDB_DATAENDPOINTS}|g; \
            s|@@SPARK_NDB_ACCESS_KEY_ID@@|\${SPARK_NDB_ACCESS_KEY_ID}|g; \
            s|@@SPARK_NDB_SECRET_ACCESS_KEY@@|\${SPARK_NDB_SECRET_ACCESS_KEY}|g" > /opt/spark/conf/spark-defaults.conf && /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077'
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077

  # PySpark Client
  spark-client:
    image: vastdataorg/spark-vast:latest
    container_name: spark-client
    restart: unless-stopped
    ports:
      - "4040:4040"  # Spark Driver Web UI
    volumes:
      - ./services/pyspark/conf/spark-defaults.conf:/tmp/spark-defaults.conf.template
    networks:
      - zeek-network
    depends_on:
      - spark-master
    env_file: .env
    command: >
      bash -c '
        cat /tmp/spark-defaults.conf.template | sed -e "s|@@SPARK_NDB_ENDPOINT@@|\\${SPARK_NDB_ENDPOINT}|g; \
            s|@@SPARK_NDB_DATAENDPOINTS@@|\${SPARK_NDB_DATAENDPOINTS}|g; \
            s|@@SPARK_NDB_ACCESS_KEY_ID@@|\${SPARK_NDB_ACCESS_KEY_ID}|g; \
            s|@@SPARK_NDB_SECRET_ACCESS_KEY@@|\${SPARK_NDB_SECRET_ACCESS_KEY}|g" > /opt/spark/conf/spark-defaults.conf && /bin/sleep infinity'
    environment:
      - SPARK_MODE=client
      - SPARK_MASTER_URL=spark://spark-master:7077

networks:
  zeek-network:
    driver: bridge
    ipam:
      config:
        - subnet: 192.168.100.0/24
